{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Inference\n",
    "\n",
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from h5py import File\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/nir_data/2017_05_22/NoSpectralCorrection/results/training03_tiedStructuredImproved/inference.hdf5'\n",
    "output_path = '/data/nir_data/2017_05_22/NoSpectralCorrection/results/training03_tiedStructuredImproved/Evaluation.pickle'\n",
    "batchsize = 256\n",
    "hist_bins = 512\n",
    "num_bands_io = 25\n",
    "num_bands_latent = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = File(path, 'r')\n",
    "input_data = f['input_data']\n",
    "latent_data = f['latent_data']\n",
    "output_data = f['output_data']\n",
    "\n",
    "iterations = (input_data.shape[0] // batchsize) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_range = {'min' : 100000, 'max': -100000}\n",
    "latent_data_range = {'min' : 100000, 'max': -100000}\n",
    "output_data_range = {'min' : 100000, 'max': -100000}\n",
    "error_data_range = {'min' : 100000, 'max': -100000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, data_range in tqdm_notebook([(input_data, input_data_range), (latent_data, latent_data_range), (output_data, output_data_range)]):\n",
    "    for i in tnrange(iterations, leave=False):\n",
    "        sample = data[i*batchsize:(i+1)*batchsize]\n",
    "        data_range['min'] = min(np.min(sample), data_range['min'])\n",
    "        data_range['max'] = max(np.max(sample), data_range['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tnrange(iterations):\n",
    "    sample = output_data[i*batchsize:(i+1)*batchsize] - input_data[i*batchsize:(i+1)*batchsize]\n",
    "    error_data_range['min'] = min(np.min(sample), error_data_range['min'])\n",
    "    error_data_range['max'] = max(np.max(sample), error_data_range['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data_range)\n",
    "print(latent_data_range)\n",
    "print(output_data_range)\n",
    "print(error_data_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second pass. Buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_min = min(input_data_range['min'], output_data_range['min'])\n",
    "io_max = max(input_data_range['max'], output_data_range['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_hist_edges = np.linspace(io_min, io_max, hist_bins)\n",
    "output_data_hist_edges = np.linspace(io_min, io_max, hist_bins)\n",
    "latent_data_hist_edges = np.linspace(latent_data_range['min'], latent_data_range['max'], hist_bins)\n",
    "error_data_hist_edges = np.linspace(error_data_range['min'], error_data_range['max'], hist_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_hist_buffer  = np.zeros( (1 + num_bands_io,     input_data_hist_edges.shape[0] - 1),  dtype=int)\n",
    "output_data_hist_buffer = np.zeros( (1 + num_bands_io,     output_data_hist_edges.shape[0] - 1), dtype=int)\n",
    "latent_data_hist_buffer = np.zeros( (1 + num_bands_latent, latent_data_hist_edges.shape[0] - 1), dtype=int)\n",
    "error_data_hist_buffer  = np.zeros( (1 + num_bands_io,     error_data_hist_edges.shape[0] - 1),  dtype=int)\n",
    "\n",
    "input_data_mean_buffer  = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)\n",
    "output_data_mean_buffer = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)\n",
    "latent_data_mean_buffer = np.zeros( (input_data.shape[0], 1 + num_bands_latent), dtype=float)\n",
    "error_data_mean_buffer  = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)\n",
    "\n",
    "input_data_sigma_buffer  = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)\n",
    "output_data_sigma_buffer = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)\n",
    "latent_data_sigma_buffer = np.zeros( (input_data.shape[0], 1 + num_bands_latent), dtype=float)\n",
    "error_data_sigma_buffer  = np.zeros( (input_data.shape[0], 1 + num_bands_io),     dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_properties(data_in, data_out, data_latent, idx):\n",
    "    def local_properties(data, hist_bins):\n",
    "        r_mean = np.mean(data)\n",
    "        r_sigma = np.std(data)\n",
    "        r_hist, _ = np.histogram(data, bins=hist_bins)\n",
    "\n",
    "        return r_mean, r_sigma, r_hist\n",
    "\n",
    "    def volume_properties(volume, hist_bins, out_mean, out_sigma, out_hist):\n",
    "        # overall\n",
    "        out_mean[-1], out_sigma[-1], tmp_hist = local_properties(volume, hist_bins)\n",
    "        out_hist[-1] += tmp_hist\n",
    "\n",
    "        # bands\n",
    "        for i, band in enumerate(np.array(volume.T, order='C')):\n",
    "            out_mean[i], out_sigma[i], tmp_hist = local_properties(band, hist_bins)\n",
    "            out_hist[i] += tmp_hist\n",
    "\n",
    "    data_error = data_in-data_out\n",
    "    \n",
    "    for data, edges, mean, sigma, hist in [\n",
    "        (data_in,     input_data_hist_edges,  input_data_mean_buffer[idx],  input_data_sigma_buffer[idx],  input_data_hist_buffer),\n",
    "        (data_out,    output_data_hist_edges, output_data_mean_buffer[idx], output_data_sigma_buffer[idx], output_data_hist_buffer),\n",
    "        (data_latent, latent_data_hist_edges, latent_data_mean_buffer[idx], latent_data_sigma_buffer[idx], latent_data_hist_buffer),\n",
    "        (data_error,  error_data_hist_edges,  error_data_mean_buffer[idx],  error_data_sigma_buffer[idx],  error_data_hist_buffer),\n",
    "    ]:\n",
    "        volume_properties(data, edges, mean, sigma, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_idx = 0\n",
    "\n",
    "for i in tnrange(iterations):\n",
    "    # loading\n",
    "    sample_input = input_data[i*batchsize:(i+1)*batchsize]\n",
    "    sample_latent = latent_data[i*batchsize:(i+1)*batchsize]\n",
    "    sample_ouput = output_data[i*batchsize:(i+1)*batchsize]\n",
    "\n",
    "    for j in tnrange(sample_input.shape[0], leave=False):\n",
    "        compute_properties(sample_input[j], sample_ouput[j], sample_latent[j], global_idx)\n",
    "        global_idx += 1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    # histogram edges\n",
    "    'input_hist_edges' : input_data_hist_edges,\n",
    "    'output_hist_edges' : output_data_hist_edges,\n",
    "    'latent_hist_edges' : latent_data_hist_edges,\n",
    "    'error_hist_edges' : error_data_hist_edges,\n",
    "\n",
    "    # histograms\n",
    "    'input_hist' : input_data_hist_buffer,\n",
    "    'output_hist' : output_data_hist_buffer,\n",
    "    'latent_hist' : latent_data_hist_buffer,\n",
    "    'error_hist' : error_data_hist_buffer,\n",
    "    \n",
    "    # means\n",
    "    'input_mean' : input_data_mean_buffer,\n",
    "    'output_mean' : output_data_mean_buffer,\n",
    "    'latent_mean' : latent_data_mean_buffer,\n",
    "    'error_mean' : error_data_mean_buffer,\n",
    "    \n",
    "    # sigmas\n",
    "    'input_sigma' : input_data_sigma_buffer,\n",
    "    'output_sigma' : output_data_sigma_buffer,\n",
    "    'latent_sigma' : latent_data_sigma_buffer,\n",
    "    'error_sigma' : error_data_sigma_buffer,\n",
    "    \n",
    "    # min max\n",
    "    'input_range' : input_data_range,\n",
    "    'latent_range' : latent_data_range,\n",
    "    'output_range' : output_data_range,\n",
    "    'error_range' : error_data_range,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'wb') as g:\n",
    "    pickle.dump(result, g, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
